### 2022-07-29
--------------------
### 크롤링   


- 웹페이지 응답상태 확인
  ```python
  requests.status_code
  ```
  응답값이 200으로 나오면 정상  

  
- 크롤링 할 때 find_all과 select를 사용하는 방식이 있는데 아래 두 개의 방식은 같은 값을 출력함.
  ```python
  soup.find_all("em", {"class":"tit"})
  soup.select('em.tit') 
  ```
    
- 과제: 장르를 입력받은 후 melon의 장르 차트에서 해당 장르의 노래와 가수를 DataFrame으로 50위까지 출력하라. (find 사용)
  ```python
  import warnings
  warnings.filterwarnings(action='ignore')
  import requests
  from bs4 import BeautifulSoup as bs
  import pandas as pd
  
  gr = input("1: 발라드\n2: 댄스\n3: 랩/힙합\n4: R&B/Soul\n5: 인디음악\n6: 록/메탈\n7: 트로트\n8: 포크/블루스\n장르를 골라 숫자로 입력하세요: ")

  header = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)"}
  html = requests.get(f'https://www.melon.com/genre/song_list.htm?gnrCode=GN0{gr}00&steadyYn=Y',  headers = header)
  soup = bs(html.text, 'html.parser')


  musics = soup.find_all("div", {"class":"ellipsis rank01"})
  singers = soup.find_all("div", {"class":"ellipsis rank02"})

  df = pd.DataFrame(columns=['singer','music'])

  for i in range(50):
    music = musics[i].find('a').text
    singer = singers[i].find('a').text
    df = df.append({"music":music, "singer":singer}, ignore_index = True)
    
  df = df.style.set_properties(**{'text-align':'left'})
  df = df.set_table_styles([dict(selector = 'th', props=[('text-align', 'left')])]) 
  
  print(df)
  ```
- 과제: 네이버 무비를 크롤링 하여 제목, 내용, 평점 순의 DataFrame을 만들어 출력하라. (select와 find 모두 사용)
  ```python
  header = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)"}

  html = requests.get('https://movie.naver.com/movie/point/af/list.naver', headers = header)
  soup = bs(html.text, 'html.parser')
  titles = soup.select('td.title')

  df = pd.DataFrame(columns=['title', 'score', 'review'])

  for i in range(10):
    title = titles[i].find('a', {'class':"movie color_b"}).text
    score = titles[i].find('em').text
    review = titles[i].find('a', {'class':"report"})
    review = str(review).split(',')[2].replace("'","")
    
    df = df.append({'title':title, 'score':score, 'review':review}, ignore_index=True)

  df = df.style.set_properties(**{'text-align':'left'})
  df = df.set_table_styles([dict(selector = 'th', props=[('text-align', 'left')])]) 
    
  print(df)
  ```

- **pd.read_html(url)**을 이용한 table 크롤링
  네이버 무비의 제목, 평점, 감상평을 1부터 100까지 **pd.read_html(url)**을 사용해 크롤링한 후 DataFrame으로 만들고 csv파일로 저장하라.
  ```python
  df = pd.DataFrame()

  for i in range(1, 101):
    url = f"https://movie.naver.com/movie/point/af/list.naver?&page={i}"
    table_pd = pd.read_html(url)
    dfi = table_pd[0] # pd.read_html로 크롤링하면 리스트형태로 반환됨. 따라서 데이터프레임으로 만들기 위해서 table_pd 뒤 [0]으로 인덱싱.

    dfi['제목'] = dfi.감상평.str.split('별점').str[0]
    dfi['평점'] = dfi.감상평.str.split('중').str[1]
    dfi['평점'] = dfi['평점'].str.split(' ').str[0]
    dfi['감상평'] = dfi.감상평.str.split('중').str[1]
    dfi['감상평']  = dfi['감상평'].str.slice(start=2, stop=-2) 
    dfi = dfi[['번호', '제목', '평점', '감상평', '글쓴이·날짜']]

  df = pd.concat([df, dfi])

  df.to_csv('‪df.csv', index=False)
  ```
