  # 머신러닝과 딥러닝의 주요 개념들 정리
  <br/>

  ## 머신러닝

  주어진 데이터에서 x와 y의 관계를 w와 b를 이용하여 식을 세우는 일을 가설이라고 한다. 문제에 대한 규칙을 가장 잘 표현하는 w와 b를 찾는 것이 중요하다. 머신 러닝은 w와 b를 찾기 위해서 실제값과 가설로부터 얻은 예측값의 오차를 계산하는 식을 세우고, 이 식의 값을 최소화하는 최적의 w와 b를 찾아낸다.
  <br/>
  <br/>

  ### - 비용 함수(Loss or Cost function)
   <br/>
  실제값과 예측값에 대한 오차에 대한 식을 목적 함수(Objective function) 또는 비용 함수(Cost function) 또는 손실 함수(Loss function) 라고 한다. 함수의 값을 최소화하거나, 최대화하거나 하는 목적을 가진 함수를 목적 함수(Objective function), 값을 최소화하려고 하면 이를 비용 함수(Cost function) 또는 손실 함수(Loss function)라고 한다. 종류로는 MAE(mean absolute error), hinge, categorical crossentropy, sparse categorical crossentropy, binary crossentropy 등이 있어 훈련시키는 모델에 적합한 손실함수를 선택하는 것이 중요하다.
  <br/>
  <br/>

  ### - 평가지표(Metric)
   <br/>
  Metric은 어떤 모델을 평가(Evaluate)하기 위해서 사용하는 값이다. 손실함수가 모델의 성능을 끌어올리기 위해서 참조하는 값, 즉 트레이닝(training, 학습)을 위해서 사용하는 나침반과 같은 존재라고 한다면, Metric은 훈련 과정을 모니터링해서 이 모델의 성능이 어느 정도이다를 알려주는 개념이다. Metric을 정한다는 것은 훈련된 모델의 성능을 평가할 때 어떤 평가지표로 평가할지를 정한다는 의미이다. 

  학습곡선을 그릴 때 손실함수와 평가지표를 에포크(epoch)마다 계산한 것을 그려주는데, 손실함수의 추이와 평가지표의 추이를 비교해보면서 모델이 과대적합(overfit) 또는 과소적합(underfit)되고 있는지 여부를 확인할 수 있다.  

  1. Accuracy: 맞춘 것 / 전체
   
  아래는  **이진 분류** 모델을 평가할 때 사용 <br/>

  1. Sensitivity: 암환자로 맞춘 것 / 암환자 수 TP / TP + FN  
   
  2. Specificity: 정상이라고 맞춘 것 / 정상환자 수 TN / TN + FP
  3. ROC Curve: True Positive Rate(TP)와 True Negative Rate(FN)의 비율을 그래프로 그린 것. 즉 모든 Threshold에 대한 Sensitivity / Specificity의 관계 그래프.
  4. AUC: ROC의 넓이

  ><br/>If correctly identifying positives is important for us, then we should choose a model with higher Sensitivity. However, if correctly identifying negatives is more important, then we should choose specificity as the measurement metric.
  <br/><br/>




  ### -  혼동 행렬(Confusion Matrix)
   <br/>

  머신 러닝에서는 맞춘 문제수를 전체 문제수로 나눈 값을 정확도(Accuracy)라고 한다. 하지만 정확도는 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주지는 않는다. 이를 위해서 사용하는 것이 혼동 행렬(Confusion Matrix)이다. 
   <br/><br/>
  | -   | 예측 참   | 예측 거짓 |
  |:--------|:--------:|--------:|
  | 실제 참   | TP | FN       |
  | 실제 거짓     | FP   | TN      |
  <br/>
 
  * True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)  
  * True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답) 
  * False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)
  * False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)

<br/><br/>

  ### -  Treshold(분류 결정 임계값)
   <br/>
  로지스틱 회귀 모형에서 특정 이메일에 관해 스팸일 확률이 0.95가 반환 되었다면 이 이메일은 스팸일 가능성이 매우 높은 메일로 예측 할 수 있다. 이와 반대로 동일한 로지스틱 회귀 모형에서 예측 점수가 0.03인 이메일이라면 이 이메일은 스팸이 아닐 가능성이 높다. 그런데 스팸이 확률이 0.6인 이메일은 처리하기가 애매하다. <br/>  

  <br/>
  이렇게 애매한 값을 이분법으로 확실히 분류를 할 기준이 필요하고, 이 기준을 Threshold라고 한다. 로지스틱 회귀 값을 이진 카테고리에 매핑(Mapping)하려면 분류 임계값(Classification Threshold, 결정 임계값이라고도 함)을 정의해야 한다. 일반적으로 이진 분류에서는 임계값을 0.5(50%)로 정하고 임계값보다 확률이 크면 True, 임계값보다 작으면 False이다. 임계값을 낮출수록 True 값이 많아진다. 

<br/><br/>

  ### - 옵티마이저(Optimizer)
 <br/>
  선형 회귀를 포함한 수많은 머신 러닝, 딥 러닝의 학습은 결국 비용 함수를 최소화하는 매개 변수인 w와 b을 찾기 위한 작업을 수행한다. 이때 사용되는 알고리즘을 옵티마이저(Optimizer) 또는 최적화 알고리즘이라고 부른다. 그리고 이 옵티마이저를 통해 적절한 w와 b를 찾아내는 과정을 머신 러닝에서 훈련(training) 또는 학습(learning)이라고 부른다. 
  <br/>
  <br/>

  ### -  ex) 선형 회귀
  - 선형회귀의 비용 함수(Cost function) : 평균 제곱 오차(MSE)
  - 선형회귀의 옵티마이저(Optimizer) : 경사하강법(Gradient Descent)
  <br/>
  <br/>

  ### -  기계학습 전 데이터의 분리 <br/><br/>

  머신 러닝을 위한 데이터를 준비했다면 기계를 학습하기 전 해당 데이터를 훈련용(Training), 검증용(Validation), 테스트용(Testing) 이렇게 세 가지로 분리하는 것이 일반적이다.  
  - 훈련 데이터는 머신 러닝 모델을 학습하는 용도이다. 테스트 데이터는 학습한 머신 러닝 모델의 성능을 평가하기 위한 용도이다.<br/><br/>
  - 검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라 모델의 성능을 조정하기 위한 용도이다. 더 정확히는 모델이 훈련 데이터에 과적합(overfitting)이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도이다. <br/><br/>   
  - 훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 튜닝(tuning) 한다. 검증용 데이터에 대해서 높은 정확도를 얻도록 하이퍼파라미터의 값을 바꿔보는 것이다.
  <br/>
  <br/>
  
  ### -  하이퍼파라미터와 파라미터(매개변수)
<br>

  - 하이퍼파라미터(초매개변수) : 모델의 성능에 영향을 주는 사람이 값을 지정하는 변수. 경사 하강법에서의 학습률(learning rate)이나, 딥 러닝에서 뉴런의 수나 층의 수와 같은 것들이 대표적인 하이퍼파라미터이다.  

  - 매개변수 : 가중치와 편향. 학습을 하는 동안 값이 계속해서 변하는 수. 가중치와 편향과 같은 매개변수는 사용자가 결정해주는 값이 아니라 모델이 학습하는 과정에서 얻어지는 값이다.
  <br/>
  <br/>

  ### -  분류(Classification)와 회귀(Regression)
   <br/>

  1) 이진 분류 문제(Binary Classification)
  이진 분류는 주어진 입력에 대해서 두 개의 선택지 중 하나의 답을 선택해야 하는 것. 종합 시험 성적표를 보고 최종적으로 합격, 불합격인지 판단하는 문제, 메일을 보고나서 정상 메일, 스팸 메일인지를 판단하는 문제 등이 이에 속한다.<br/><br/>

  2) 다중 클래스 분류(Multi-class Classification)
  다중 클래스 분류는 주어진 입력에 대해서 세 개 이상의 선택지 중에서 답을 선택해야 하는 것. 예를 들어 서점 직원이 일을 하는데 과학, 영어, IT, 학습지, 만화라는 레이블이 붙어있는 5개의 책장이 있다고 하고 새 책이 입고되면, 이 책은 다섯 개의 책장 중에서 분야에 맞는 적절한 책장에 책을 넣어야 한다. 이 경우는 현실에서의 다중 클래스 분류 문제라고 할 수 있다.<br/><br/>

  3) 회귀 문제(Regression)
  회귀 문제는 분류 문제처럼 둘 중 하나를 선택해야 한다거나, 책이 입고되었을 때 5개의 책장 중 하나의 책장을 골라야하는 경우처럼 정답이 몇 개의 정해진 선택지 중에서 정해져 있는 경우가 아니라 어떠한 연속적인 값의 범위 내에서 예측값이 나오는 경우를 말한다.  
              
  ><br/>예를 들어 역과의 거리, 인구 밀도, 방의 개수 등을 입력하면 부동산 가격을 예측하는 머신 러닝 모델이 있다고 하면 머신 러닝 모델이 부동산 가격을 7억 8,456만 3,450원으로 예측하는 경우도 있을 것이고, 8억 1257만 300원으로 예측하는 경우도 있을 수 있다. 즉, 특정 값의 범위 내에서는 어떤 숫자도 나올 수 있다. 기존의 분류 문제와 같이 분리된(비연속적인) 답이 결과가 아니라 연속된 값을 결과로 가지는 이러한 문제를 회귀 문제라고 부른다. 회귀 문제의 예시로 시계열 데이터(Time Series Data)를 이용한 주가 예측, 생산량 예측, 지수 예측 등이 있다.
  <br/>
  <br/>

  ### -  원-핫 인코딩(One-Hot Encoding)  
 <br/>
  컴퓨터는 문자보다는 숫자를 더 잘 처리한다. 이를 위해 자연어 처리에서는 문자를 숫자로 바꾸는 여러가지 기법들이 있다. 원-핫 인코딩은 그 기법들 중에서 단어를 표현하는 가장 기본적인 표현 방법이다.   
  원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식이다. 이렇게 표현된 벡터를 원-핫 벡터(One-Hot vector)라고 한다.
  <br/>
  <br/>

  ### -  소프트맥스 회귀(Softmax Regression)
 <br/>

  
  이진 분류가 두 개의 선택지 중 하나를 고르는 문제라면, 다중 클래스 분류는 세 개 이상의 선택지 중 하나를 고르는 문제이다. 로지스틱 회귀를 통해 2개의 선택지 중에서 1개를 고르는 이진 분류(Binary Classification)문제를 푼다면 3개 이상의 선택지 중에서 1개를 고르는 다중 클래스 분류 문제는 소프트맥스 회귀를 통해 풀 수 있다.     
  
  소프트맥스 함수는 선택해야 하는 선택지의 총 개수를 k라고 할 때, k차원의 벡터를 입력받아 각 클래스에 대한 확률을 추정한다. 다수의 클래스를 분류하는 문제에서는 이진 분류처럼 2개의 숫자 레이블이 아니라 클래스의 개수만큼 숫자 레이블이 필요하다. 이때 생각해볼 수 있는 레이블링 방법은 분류해야 할 클래스 전체에 정수 인코딩을 하는 것이다. 예를 들어서 분류해야 할 레이블이 {red, green, blue}와 같이 3개라면 각각 0, 1, 2로 레이블한다. 또는 분류해야 할 클래스가 4개고 인덱스를 숫자 1부터 시작하고 싶다면 {baby, child, adolescent, adult}라면 1, 2, 3, 4로 레이블을 해볼 수 있다.  

  그런데 일반적인 다중 클래스 분류 문제에서 레이블링 방법으로는 위와 같은 정수 인코딩이 아니라 원-핫 인코딩을 사용하는 것이 보다 클래스의 성질을 잘 표현하였다고 할 수 있다. 그 이유는 정수 인코딩과 달리 원-핫 인코딩은 분류 문제 모든 클래스 간의 관계를 균등하게 분배하기 때문이다. 물론 각 클래스가 순서의 의미를 갖고 있어 회귀를 통해 분류 문제를 풀 수 있는 경우는 정수 인코딩의 순서 정보가 도움이 된다.
  <br/>
  <br/>

  ### -  훈련 데이터의 오차와 테스트 데이터의 오차는 손실이라고도 부른다.
  <br/>
  <br/>

  ### -  과적합 방지를 고려한 일반적인 딥 러닝 모델의 학습 과정<br/><br/>

  1. 주어진 데이터를 훈련 데이터, 검증 데이터, 테스트 데이터로 나눈다. 가령, 6:2:2 비율로 나눌 수 있다. 
   
  2. 훈련 데이터로 모델을 학습한다. (에포크 +1)
  3. 검증 데이터로 모델을 평가하여 검증 데이터에 대한 정확도와 오차(loss)를 계산한다.
  4. 검증 데이터의 오차가 증가하였다면 과적합 징후이므로 학습 종료 후 Step 5로 이동, 아니라면 Step 2.로 재이동한다.
  5. 모델의 학습이 종료되었으니 테스트 데이터로 모델을 평가한다.
  <br/>
  <br/>
    

  ### -  손실 함수(Loss function)
   <br/>
  손실 함수는 실제값과 예측값의 차이를 수치화해주는 함수이다. 이 두 값의 차이. 즉, 오차가 클 수록 손실 함수의 값은 크고 오차가 작을 수록 손실 함수의 값은 작아진다. 회귀에서는 평균 제곱 오차, 분류 문제에서는 크로스 엔트로피를 주로 손실 함수로 사용한다. 손실 함수의 값을 최소화하는 두 개의 매개변수인 가중치 w와 편향 b의 값을 찾는 것이 딥 러닝의 학습 과정이므로 손실 함수의 선정은 매우 중요하다.  
    <br/>
    
  1) 평균 제곱 오차, MSE(Mean Squared Error, MSE): 선형 회귀, 즉 연속형 변수를 예측할 때 사용.  
   
  2) 이진 크로스 엔트로피(Binary Cross-Entropy): 이항 교차 엔트로피라고도 부르는 손실 함수. 출력층에서 시그모이드 함수를 사용하는 이진 분류, 로지스틱 회귀에서 사용.
  3) 카테고리칼 크로스 엔트로피(Categorical Cross-Entropy): 출력층에서 소프트맥스 함수를 사용하는 다중 클래스 분류(Multi-Class Classification)일 경우 사용.
  <br/>
  <br/>
  
  ### -  배치 크기(Batch Size)에 따른 경사 하강법
   <br/>
  손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라진다. 여기서 배치(Batch)라는 개념에 대한 이해가 필요한데, 배치는 가중치 등의 매개 변수의 값을 조정하기 위해 사용하는 데이터의 양을 말한다. 전체 데이터를 가지고 매개 변수의 값을 조정할 수도 있고, 정해준 양의 데이터만 가지고도 매개 변수의 값을 조정할 수 있다. <br/><br/>

  1) 배치 경사 하강법(Batch Gradient Descent): 가장 기본적인 경사 하강법. 배치 경사 하강법은 옵티마이저 중 하나로 오차(loss)를 구할 때 전체 데이터를 고려. 딥 러닝에서는 전체 데이터에 대한 한 번의 훈련 횟수를 1 에포크라고 하는데, 배치 경사 하강법은 한 번의 에포크에 모든 매개변수 업데이트를 단 한 번 수행. 전체 데이터를 고려해서 학습하므로 한 번의 매개 변수 업데이트에 시간이 오래 걸리며, 메모리를 크게 요구한다는 단점이 있다.  
  
  2) 배치 크기가 1인 확률적 경사 하강법(Stochastic Gradient Descent, SGD): 매개변수 값을 조정 시 전체 데이터가 아니라 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 방법. 더 적은 데이터를 사용하므로 더 빠르게 계산 가능. 확률적 경사 하강법은 매개변수의 변경폭이 불안정하고, 배치 경사 하강법보다 정확도가 낮을 수도 있지만 하나의 데이터에 대해서만 메모리에 저장하면 되므로 자원이 적은 컴퓨터에서도 쉽게 사용 가능.  
  
  3) 미니 배치 경사 하강법(Mini-Batch Gradient Descent): 가장 많이 사용하는 경사 하강법. 전체 데이터도, 1개의 데이터도 아닐 때, 배치 크기를 지정하여 해당 데이터 개수만큼에 대해서 계산하여 매개 변수의 값을 조정하는 경사 하강법. 전체 데이터를 계산하는 것보다 빠르며, SGD보다 안정적이라는 장점이 있다. 배치 크기는 일반적으로 2의 n제곱에 해당하는 숫자로 선택하는 것이 보편적. 만약, model.fit()에서 배치 크기를 별도로 지정해주지 않을 경우에 기본값은 2의 5제곱에 해당하는 숫자인 32로 설정된다.
  <br/>
  <br/>
  
  ### -  에포크와 배치 크기와 이터레이션(Epochs and Batch size and Iteration)
   <br/>

  사람마다 동일한 문제지와 정답지를 주더라도 공부 방법은 사실 천차만별입니다. 어떤 사람은 문제지 하나를 다 풀고 나서 정답을 채점하는데 어떤 사람은 문제지의 문제를 10개 단위로 끊어서 공부합니다. 문제 10개를 풀고 채점하고 다시 다음 문제 10개를 풀고 채점하고 반복하는 방식으로 학습하는 방식입니다. 또한 게으른 사람은 문제지를 세 번 공부하는데, 성실한 사람은 문제지의 문제를 달달 외울만큼 문제지를 100번 공부합니다. 기계도 똑같습니다. 같은 문제지와 정답지를 주더라도 공부 방법을 다르게 설정할 수 있습니다.
   <br/> 
    
 <br/>

  #### 1) 에포크(Epoch)
   <br/>
  에포크란 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태를 말한다. 전체 데이터를 하나의 문제지에 비유한다면 문제지의 모든 문제를 끝까지 다 풀고, 정답지로 채점을 하여 문제지에 대한 공부를 한 번 끝낸 상태이다.
만약 에포크가 50이라고 하면, 전체 데이터 단위로는 총 50번 학습한다. 문제지에 비유하면 문제지를 50번 푼 셈이다. 이 에포크 횟수가 지나치거나 너무 적으면 과적합이나 과소적합이 발생할 수 있다.
   <br/><br/>
   
   #### 2) 배치 크기(Batch size)
   <br/>
  배치 크기는 몇 개의 데이터 단위로 매개변수를 업데이트 하는지를 말한다. 현실에 비유하면 문제지에서 몇 개씩 문제를 풀고나서 정답지를 확인하느냐의 문제이다. 사람은 문제를 풀고 정답을 보는 순간 부족했던 점을 깨달으며 지식이 업데이트 된다면 기계 입장에서는 실제값과 예측값으로부터 오차를 계산하고 옵티마이저가 매개변수를 업데이트한다. 중요한 포인트는 업데이트가 시작되는 시점이 정답지/실제값을 확인하는 시점이라는 것이다. <br/><br/>
  
  사람이 2,000 문제가 수록되어있는 문제지의 문제를 200개 단위로 풀고 채점한다고 하면 이때 배치 크기는 200이다. 기계는 배치 크기가 200이면 200개의 샘플 단위로 가중치를 업데이트 한다. <br/><br/>

  배치 크기와 배치의 수는 다른 개념이다. 전체 데이터가 2,000일때 배치 크기를 200으로 준다면 배치의 수는 10이다. 이는 에포크에서 배치 크기를 나눠준 값(2,000/200 = 10)이기도 하다. 이때 배치의 수를 이터레이션이라고 한다.  
    <br/>
  #### 3) 이터레이션(Iteration) 또는 스텝(Step)
  <br/>
  이터레이션이란 한 번의 에포크를 끝내기 위해서 필요한 배치의 수를 말한다. 또는 한 번의 에포크 내에서 이루어지는 매개변수의 업데이트 횟수이기도 하다. 전체 데이터가 2,000일 때 배치 크기를 200으로 한다면 이터레이션의 수는 총 10이다. 이는 한 번의 에포크 당 매개변수 업데이트가 10번 이루어진다는 것을 의미한다. 배치 크기가 1인 확률적 경사 하강법을 이 개념을 가지고 다시 설명하면 배치 크기가 1이므로 모든 이터레이션마다 하나의 데이터를 선택하여 경사 하강법을 수행한다. 이터레이션은 스텝(Step)이라고 부르기도 한다. 
  <br/>
  <br/>
  
  ### -  순전파(Forward Propagation)와 역전파(BackPropagation)
   <br/>

  인공 신경망이 순전파 과정을 진행하여 예측값과 실제값의 오차를 계산한다면 역전파 과정에서는 경사 하강법을 사용하여 가중치를 업데이트한다. 순전파 과정에서 각 입력은 입력층에서 은닉층 방향으로 향하면서 각 입력에 해당하는 가중치와 곱해지고, 결과적으로 가중합으로 계산되어 은닉층 뉴런의 활성함수의 입력값이 된다.    
  
  출력층 뉴런에서 활성함수를 지난 값은 그 인공 신경망이 최종적으로 계산한 출력값이다. 실제값을 예측하기 위한 값으로서 예측값이라고도 부른다. 이 후에 해야할 일은 예측값과 실제값의 오차를 계산하기 위한 오차 함수를 선택하는 것이다.  
  
  순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트해간다. 인공 신경망의 학습은 오차를 최소화하는 가중치를 찾는 목적으로 순전파와 역전파를 반복하는 것을 말한다.  
  <br/>
  <br/> 
 
  ### -  과적합(Overfitting)을 막는 방법들
  <br/> 

  1. 데이터의 양을 늘리기: 모델은 데이터의 양이 적을 경우, 해당 데이터의 특정 패턴이나 노이즈까지 쉽게 암기하기 되므로 과적합 현상이 발생할 확률이 늘어난다. 데이터의 양을 늘릴 수록 모델은 데이터의 일반적인 패턴을 학습하여 과적합을 방지할 수 있다.  
    
  2. 모델의 복잡도 줄이기: 인공 신경망의 복잡도는 은닉층(hidden layer)의 수나 매개변수의 수 등으로 결정된다. 과적합 현상이 포착되었을 때, 인공 신경망 모델에 대해서 할 수 있는 한 가지 조치는 인공 신경망의 복잡도를 줄이는 것이다.  
   
  3. 가중치 규제(Regularization) 적용하기: 복잡한 모델이 간단한 모델보다 과적합될 가능성이 높다. 간단한 모델은 적은 수의 매개변수를 가진 모델을 말합니다. 복잡한 모델을 좀 더 간단하게 하는 방법으로 가중치 규제가 있다. 
    - L1 규제 : 가중치 w들의 절대값 합계를 비용 함수에 추가
    - L2 규제 : 모든 가중치 w들의 제곱합을 비용 함수에 추가  
  
  4. 드롭아웃(Dropout): 드롭아웃은 학습 과정에서 신경망의 일부를 사용하지 않는 방법이다. 예를 들어 드롭아웃의 비율을 0.5로 한다면 학습 과정마다 랜덤으로 절반의 뉴런을 사용하지 않고, 절반의 뉴런만을 사용한다. 드롭아웃은 신경망 학습 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적이다. 학습 시에 인공 신경망이 특정 뉴런 또는 특정 조합에 너무 의존적이게 되는 것을 방지하고, 매번 랜덤 선택으로 뉴런들을 사용하지 않으므로 서로 다른 신경망들을 앙상블하여 사용하는 것 같은 효과를 내어 과적합을 방지한다.
  <br/>
  <br/>
  
  ### -  기울기 소실(Gradient Vanishing)과 폭주(Exploding)
   <br/>
  깊은 인공 신경망을 학습하다보면 역전파 과정에서 입력층으로 갈 수록 기울기(Gradient)가 점차적으로 작아지는 현상이 발생할 수 있다. 입력층에 가까운 층들에서 가중치들이 업데이트가 제대로 되지 않으면 결국 최적의 모델을 찾을 수 없게 되는데 이를 기울기 소실이라고 한다.
  반대로 기울기가 점차 커지며 가중치들이 비정상적으로 큰 값이 되면서 결국 발산되기도 하는데 이를 기울기 폭주라고 한다. <br/> <br/>
  
  ><br/>은닉층에서는 시그모이드 함수를 사용하지 마세요. Leaky ReLU를 사용하면 모든 입력값에 대해서 기울기가 0에 수렴하지 않아 죽은 ReLU 문제를 해결합니다. 은닉층에서는 ReLU나 Leaky ReLU와 같은 ReLU 함수의 변형들을 사용하세요.
  <br/> <br/>
  
  ### -  가중치 초기화(Weight initialization)
   <br/>
  같은 모델을 훈련시키더라도 가중치가 초기에 어떤 값을 가졌느냐에 따라서 모델의 훈련 결과가 달라지기도 한다. 가중치 초기화만 적절히 해줘도 기울기 소실 문제과 같은 문제를 완화시킬 수 있다. <br/> <br/>

  1) 세이비어 초기화(Xavier Initialization): 균등 분포(Uniform Distribution)와 정규 분포(Normal distribution)로 초기화 하는 두 가지 경우로 나뉘며, 이전 층의 뉴런 개수와 다음 층의 뉴런 개수를 가지고 식을 운다. 여러 층의 기울기 분산 사이에 균형을 맞춰서 특정 층이 너무 주목을 받거나 다른 층이 뒤쳐지는 것을 막는다. 
   세이비어 초기화는 시그모이드 함수나 하이퍼볼릭 탄젠트 함수와 같은 S자 형태인 활성화 함수와 함께 사용할 경우에는 좋은 성능을 보이지만, ReLU와 함께 사용할 경우에는 성능이 좋지 않다. ReLU 함수 또는 ReLU의 변형 함수들을 활성화 함수로 사용할 경우에는 He 초기화를 사용하는 것이 좋다.  
   
  2) He 초기화(He initialization): He 초기화(He initialization)는 세이비어 초기화와 같이 정규 분포와 균등 분포 두 가지 경우로 나뉘지만 He 초기화는 세이비어 초기화와 다르게 다음 층의 뉴런의 수를 반영하지 않는다. 
  <br/>
  <br/>
  
  ### -  배치 정규화(Batch Normalization)
   <br/>
  ReLU 계열의 함수와 He 초기화를 사용하는 것만으로도 어느 정도 기울기 소실과 폭주를 완화시킬 수 있지만, 이 두 방법을 사용하더라도 훈련 중에 언제든 다시 발생할 수 있다. 기울기 소실이나 폭주를 예방하는 또 다른 방법으로는 배치 정규화가 있다. 배치 정규화(Batch Normalization)는 표현 그대로 한 번에 들어오는 배치 단위로 정규화하는 것을 말한다. 이는 인공 신경망의 각 층에 들어가는 입력을 평균과 분산으로 정규화하여 학습을 효율적으로 만든다.  
  배치 정규화는 각 층에서 활성화 함수를 통과하기 전에 수행된다. 배치 정규화를 요약하면 입력에 대해 평균을 0으로 만들고, 정규화를 한다. 그리고 정규화 된 데이터에 대해서 스케일과 시프트를 수행한다. 이때 두 개의 매개변수 γ와 β를 사용하는데, γ는 스케일을 위해 사용하고, β는 시프트를 하는 것에 사용하며 다음 레이어에 일정한 범위의 값들만 전달되게 한다.  
   <br/> <br/>
  단 배치 정규화는 미니 배치 크기에 의존적이라는 단점이 있다. 배치 정규화는 너무 작은 배치 크기에서는 잘 동작하지 않을 수 있는데 단적으로 배치 크기를 1로 한다면 분산은 0이 된다. 작은 미니 배치에서는 배치 정규화의 효과가 극단적으로 작용하어 훈련에 악영향을 줄 수 있다. 배치 정규화를 적용할때는 작은 미니 배치보다는 크기가 어느정도 되는 미니 배치에서 하는 것이 좋다. 
  <br/>
  <br/>

  ### - 모멘텀(momentem)
   <br/>
   > Momentum is an extension to the gradient descent optimization algorithm that allows the search to build inertia in a direction in the search space and overcome the oscillations of noisy gradients and coast across flat spots of the search space.
   
   모멘텀은 신경망의 학습 안정성과 속도를 높여 학습을 잘 시키기 위해 사용된다. 모멘텀은 가중치를 갱신할 때 델타 규칙에 모멘텀을 추가로 더한다. 모멘텀을 사용하면 가중치 값이 바로 바뀌지 않고 어느 정도 일정한 방향을 유지하면서 움직이게 된다. 또한 가속도처럼 같은 방향으로 더 많이 변화시켜 학습속도를 높여줘 빠른 학습을 하게 한다.
  <br/> <br/>


  ### - 오즈비
   <br/>
  오즈는 특정 이벤트가 발생할 확률이다. 오즈비는 p/(1-p)로 나타낼 수 있다. 여기서 p는 양성 샘플일 확률이며 양성 샘플은 '예측 대상'을 말한다. ex) 환자가 어떤 질병을 가지고 있을 확률. 클래스 레이블 y=1인 샘플. 이 오즈비에 로그 함수(로그 오즈)를 취해 로짓(logit)함수를 정의한다.
  
  ![로그 함수](https://thebook.io/img/080223/eq-563.jpg)
  <br/> <br/>

  ### - 필터의 역할
   <br/>
   필터는 계산 위치를 옮겨가며, 좌측과 우측의 계산 결과를 서로 더해준다. 이러한 계산을 모든 부분에 돌아가며 한다면 해당 위치에서 필터 형태 크기의 픽셀들이 어떤 영향을 가지고 있는지를 알 수 있다.(필터 크기가 3개면, 원소 3개를 단위로 그 영향력과 형태를 알아보는 것이고, 그 이상도 같은 원리)

   딥러닝은 conv의 필터도 일종의 파라미터로 보고, 오차역전파와 기계학습을 통해 이를 학습시킨다. 스스로 앞의 계층에서는 선이나 점과 같은 기본적인 정보를 추출하는 필터를 만들어내고, 후방으로 갈수록, 해당 이미지가 가진 독특한 패턴들을 추출하는 필터를 만들어낸다.
  <br/> <br/>

  ### - keras 모듈의 합성곱 방식
  |  | 합성곱의 방향 | 출력값 |
  |:-----:|:--------:|:-----:|
  |Conv1D|한 방향(가로 혹은 세로)|1D Array(Vector)|
  |Conv2D|두 방향(x, y)|2D Array(Matrix|

  - 합성곱 신경망 적용 코드
```python
  INPUT_SIZE = (1,28,28) # 28행 28열의 2차원 행렬
  input = tf.placeholder(tf.float32, shape=INPUT_SIZE)
  conv = tf.keras.layers.Conv1D( # 연산의 출력값이 1차원 벡터이므로 Conv1D를 사용
  filters=10, # 필터는 10개를 적용
  kernel_size=3, # kernel_size는 3, 내부에서는 저절로 (1, 28, 3) 형태의 필터가 생성되어 적용됨
  padding='same',
  activation=tf.nn.relu)(input)
```
  <br/> <br/>

    ### - 오즈비
   <br/>
  오즈는 특정 이벤트가 발생할 확률이다. 오즈비는 p/(1-p)로 나타낼 수 있다. 여기서 p는 양성 샘플일 확률이며 양성 샘플은 '예측 대상'을 말한다. ex) 환자가 어떤 질병을 가지고 있을 확률. 클래스 레이블 y=1인 샘플. 이 오즈비에 로그 함수(로그 오즈)를 취해 로짓(logit)함수를 정의한다.
  
  ![로그 함수](https://thebook.io/img/080223/eq-563.jpg)
  <br/> <br/>
